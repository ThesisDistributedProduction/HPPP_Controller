<?xml version="1.0" encoding="UTF-8"?>

<dds>
    <!--qos_library name="DefaultLibrary" -->
    <qos_library name="Turbine_Library">
        <!-- qos_profile name="ParticipantQOS" is_default_participant_factory_profile="true" -->
        <qos_profile name="ParticipantQOS" is_default_qos="true">

            <participant_factory_qos>
				<!-- relevant for siemens -->
                <logging>
                    <verbosity>WARNING</verbosity>
                    <category>PLATFORM</category>
                    <print_format>VERBOSE_TIMESTAMPED</print_format>
                    <output_file>ddsadaptor.log</output_file>
                </logging>
            </participant_factory_qos>

            <participant_qos>
                <participant_name>
                    <name>TurbineParticipant</name>
                    <role_name>TurbineParticipantRole</role_name>
                </participant_name>
				<!-- db cleanup after shutdown of a participant. Db is the db local and remote entities -->
                <database>
                    <shutdown_cleanup_period>
                        <sec>DURATION_ZERO_SEC</sec>
                        <nanosec>1</nanosec>
                    </shutdown_cleanup_period>
                </database>
                <transport_builtin>
                     <!--
                         The transport_builtin mask identifies which builtin
                         transports the domain participant uses. The default value
                         is UDPv4 | SHMEM.
                     -->
                    <mask>UDPv4</mask>
                </transport_builtin>
                <receiver_pool>
                    <buffer_size>LENGTH_AUTO</buffer_size>
                </receiver_pool>
                <property>
                    <value>
                        <!--element>
                            <name>dds.transport.UDPv4.builtin.multicast_enabled</name>
                            <value>0</value>
                        </element -->
						<element>
							<name>dds.transport.UDPv4.builtin.parent.message_size_max</name>
							<value>65535</value>
						</element>
						<element>
							<name>dds.transport.UDPv4.builtin.send_socket_buffer_size </name>
							<value>65535</value>
						</element>
						<element>
							<name>dds.transport.UDPv4.builtin.recv_socket_buffer_size</name>
							<value>2097152</value>
						</element>
					</value>
                </property>
            </participant_qos>
			
			<topic_qos name="TurbineTopicQos">
				<!-- 
				 DDS_PROTOCOL_ACKNOWLEDGMENT_MODE (Default) = No application-level acknowledgement. 
				 AckNack sker gennem Real-Time Publish-Subscribe (RTPS) reliability protocol. -->
				<reliability>
				  <kind>DDS_RELIABLE_RELIABILITY_QOS</kind>
				</reliability>
			</topic_qos>
			
			<datawriter_qos>
				<publication_name>
					<name>TurbineDataWriter</name>
				</publication_name>
				
				<!-- StÃ¸rrelse af reliability buffer -->
				<history>
					<kind>KEEP_ALL_HISTORY_QOS</kind>
				</history>
				
                <!-- HIGH THROUGHPUT
                We're limiting resources based on the number of batches. We
                could limit resources on a per-sample basis too if we wanted
                to; we'd probably to set the value based on how many samples
                we expect to be in each batch. Rather than come up with a
                heuristic, however, it's more straightforward to override
                this value to leave the value unlimited. (If you were to set
                both, the first limit to be hit would take effect.)
                
                <resource_limits>
                    <max_samples>LENGTH_UNLIMITED</max_samples>
                </resource_limits>-->
				
				<resource_limits>
                    <max_samples_per_instance>20</max_samples_per_instance>
                </resource_limits>
                <reliability>
                    <max_blocking_time>
                        <sec>5</sec>
                        <nanosec>0</nanosec>
                    </max_blocking_time>
                </reliability>
				<!-- <lifespan>
					<duration>
						 <sec>0</sec>
						 <nanosec>150000000</nanosec>
					</duration>
				</lifespan> -->
				
				<!-- <liveliness>
					<lease_duration>
						<sec>0</sec>
						<nanosec>300000000</nanosec>
					</lease_duration>
				</liveliness> --> 
				
				<!--
                The following parameters tune the behavior of the reliability
                protocol. Setting them is not required in order to achieve
                strict reliability but is beneficial from a performance
                standpoint. 
                -->
                <protocol>
                    <rtps_reliable_writer>
                        <!--
                        When the writer's cache gets down to this number of
                        samples, it will slow the rate at which it sends
                        heartbeats to readers.
                        -->
                        <low_watermark>5</low_watermark>
                        <!--
                        When the writer's cache is filled to this level, it
                        will begin sending heartbeats at a faster rate in
                        order to spur faster acknowledgement (positive or
                        negative) of its samples to allow it to empty its
                        cache and avoid blocking.
                        -->
                        <high_watermark>15</high_watermark>

                        <!--
                        If the number of samples in the writer's cache hasn't
                        risen to high_watermark, this is the rate at which
                        the DataWriter will send out periodic heartbeats.
                        -->
                        <heartbeat_period>
                            <!-- 100 milliseconds: -->
                            <sec>0</sec>
                            <nanosec>100000000</nanosec>
                        </heartbeat_period>
                        <!--
                        If the number of samples in the writer's cache has
                        risen to high_watermark, and has not yet fallen to
                        low_watermark, this is the rate at which the writer
                        will send periodic heartbeats to its readers.
                        -->
                        <fast_heartbeat_period>
                            <!-- 10 milliseconds: -->
                            <sec>0</sec>
                            <nanosec>10000000</nanosec>
                        </fast_heartbeat_period>
                        <!--
                        If a durable reader starts up after the writer
                        already has some samples in its cache, this is the
                        rate at which it will heartbeat the new reader. It
                        should generally be a shorter period of time than the
                        normal heartbeat period in order to help the new
                        reader catch up.
                        -->
                        <late_joiner_heartbeat_period>
                            <!-- 10 milliseconds: -->
                            <sec>0</sec>
                            <nanosec>10000000</nanosec>
                        </late_joiner_heartbeat_period>

                        <!--
                        The number of times a reliable writer will send a
                        heartbeat to a reader without receiving a response
                        before it will consider the reader to be inactive and
                        no longer await acknowledgements before discarding
                        sent data.

                        On a non-real-time operating system like Windows or
                        Linux, a poorly behaving process could monopolize the
                        CPU for several seconds. Therefore, in many cases a
                        value that yields a "grace period" of several seconds
                        is a good choice.
                        -->
                        <max_heartbeat_retries>500</max_heartbeat_retries>

                        <!--
                        When a DataWriter receives a negative acknowledgement
                        (NACK) from a DataReader for a particular data sample,
                        it will send a repair packet to that reader.

                        The amount of time the writer waits between receiving
                        the NACK and sending the repair will be a random
                        value in between the minimum and maximum values
                        specified here. Narrowing the range, and shifting it
                        towards zero, will make the writer more reactive.
                        However, by leaving some delay, you increase the
                        chances that the writer will learn of additional
                        readers that missed the same data, in which case it
                        will be able to send a single multicast repair
                        instead of multiple unicast repairs, thereby using
                        the available network bandwidth more efficiently. The
                        higher the number of readers on the topic, and the
                        greater the load on your network, the more you should
                        consider specifying a range here.
                        -->
                        <min_nack_response_delay>
                            <sec>0</sec>
                            <nanosec>0</nanosec>
                        </min_nack_response_delay>
                        <max_nack_response_delay>
                            <sec>0</sec>
                            <nanosec>0</nanosec>
                        </max_nack_response_delay>
                        <!--
                        Set the maximum number of unacknowedged samples 
                        (batches) in the DataWriter's queue equal to the max 
                        number of batches, to limit how far ahead a writer can 
                        get ahead of its potentially slow readers.
                        -->
                        <min_send_window_size>32</min_send_window_size>
                        <max_send_window_size>32</max_send_window_size>
                    </rtps_reliable_writer>
                </protocol>
				 
			</datawriter_qos>
			

			<!-- QoS used to configure the data reader created in the example code -->				
			<datareader_qos>
				<subscription_name>
					<name>TurbineDataReader</name>
				</subscription_name>
				
				<!-- Vi er ikke interesserede i historik -->
				<history>
					<kind>KEEP_LAST_HISTORY_QOS</kind>
					<depth>1</depth>
				</history>
                <!--
                The following parameters tune the behavior of the reliability
                protocol. Setting them is not required in order to achieve
                strict reliability but is beneficial from a performance
                standpoint. 
                -->

                <protocol>
                    <rtps_reliable_reader>
                        <!--
                        When the DataReader receives a heartbeat from a
                        DataWriter (indicating (a) that the DataWriter still
                        exists on the network and (b) what sequence numbers
                        it has published), the following parameters indicate
                        how long it will wait before replying with a positive
                        (assuming they aren't disabled) or negative
                        acknowledgement.

                        The time the reader waits will be a random duration
                        in between the minimum and maximum values. Narrowing
                        this range, and shifting it towards zero, will make
                        the system more reactive. However, it will increase
                        the chance of (N)ACK spikes. The higher the number of
                        readers on the topic, and the greater the load on
                        your network, the more you should consider specifying
                        a range here.
                        -->
                        <min_heartbeat_response_delay>
                            <sec>0</sec>
                            <nanosec>0</nanosec>
                        </min_heartbeat_response_delay>
                        <max_heartbeat_response_delay>
                            <sec>0</sec>
                            <nanosec>0</nanosec>
                        </max_heartbeat_response_delay>
                    </rtps_reliable_reader>
                </protocol>
			</datareader_qos>
        </qos_profile>
	</qos_library>
</dds>
